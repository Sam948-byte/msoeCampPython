{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this walk-through was adapted from the following two tutorials, check them out for more info:\n",
    "# https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "# https://towardsdatascience.com/exploring-classifiers-with-python-scikit-learn-iris-dataset-2bcb490d2e1b\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(iris, test_size = .2, stratify = iris['class'], random_state = 0)\n",
    "# splits the data into a training and testing set\n",
    "# test_size = .3 makes the test set 30% of the data\n",
    "# stratify = iris['class'] makes the classes equally represented in the training/testing sets\n",
    "# setting a random state ensures that the data will be divided the same way each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"class\"].value_counts()\n",
    "# in fact we do have balanced training/testing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualize the training set\n",
    "train.plot(kind = \"box\", subplots = True, layout = (2,2), sharey = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train, hue=\"class\", palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split yourdata sets into predictive attributs (x)\n",
    "# and the class you are trying to predict (y)\n",
    "\n",
    "x_train = train[['sepal_length','sepal_width', 'petal_length', 'petal_width']]\n",
    "y_train = train['class']\n",
    "\n",
    "x_test = test[['sepal_length','sepal_width', 'petal_length', 'petal_width']]\n",
    "y_test = test['class']\n",
    "\n",
    "#first model we will try is a decision tree\n",
    "mod_dt = DecisionTreeClassifier(max_depth = 3,random_state = 1) #declare model \"estimator\"\n",
    "mod_dt.fit(x_train,y_train) #fit the model to your data\n",
    "y_pred=mod_dt.predict(x_test) #use your \"fitted\" model to predict labels for the test data\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good was the model at predicting?\n",
    "metrics.accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets visualize the tree\n",
    "plt.figure(figsize = (5,5), dpi = 200)\n",
    "plot_tree(mod_dt,feature_names=x_train.columns,class_names=mod_dt.classes_, filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets look at precision, recall, and F1\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try a different model\n",
    "Naive Bayes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_nb = GaussianNB()\n",
    "mod_nb.fit(x_train,y_train) #fit the model to your data\n",
    "y_pred2=mod_nb.predict(x_test) #use your \"fitted\" model to predict labels for the test data\n",
    "# how good was the model at predicting?\n",
    "metrics.accuracy_score(y_pred2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refit the model with just the petal attributes\n",
    "\n",
    "mod_nb.fit(x_train[[\"petal_length\", \"petal_width\"]], y_train)\n",
    "y_pred3 = mod_nb.predict(x_test[[\"petal_length\", \"petal_width\"]])\n",
    "print(\"accuracy: \", metrics.accuracy_score(y_pred3,y_test))\n",
    "#lets look at precision, recall, and F1\n",
    "print(metrics.classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does **better** using only two features. This implies that the model may be \"overfitting\" when using all 4 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we randomly got a bad \"split\" of the data into training and testing sets?\n",
    "There are solutions to this problem, one of the most common is called **k-fold cross validation**. K-fold cross validation divides your data into k smaller data sets, then trains the model on k different subsets of the data.\n",
    "\n",
    "Lets test out a few different models using k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different models to test\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(name, round(cv_results.mean(),3), round(cv_results.std(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: build a model to predict basketball games!\n",
    "Download the basketballData.csv file from Canvas. Choose what features (columns) you think are most predictive and choose a model from above and try to build the best model you can! Remember, the basic format for modeling in python is:\n",
    "\n",
    "1) divide your data into a training and testing set\n",
    "\n",
    "2) declare a model esitmator\n",
    "\n",
    "3) \"fit\" the model\n",
    "\n",
    "4) evaluate the model\n",
    "\n",
    "For information about what each column means, see: https://www.sports-reference.com/cbb/seasons/2021-school-stats.html\n",
    "\n",
    "The first step has already been done for you below. The column you are interested in predicting is 'Team1Win?'. Don't worry about trying to do k-fold cross validation. Just choose parameters and try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basketballData = pd.read_csv(\"basketballData.csv\")\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "\n",
    "basketballData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into training and testing\n",
    "train, test = train_test_split(basketballData, test_size = .2, stratify = basketballData['Team1Win?'], random_state = 0)\n",
    "\n",
    "#divide into x and y\n",
    "x_train = train[[\"Team1SRS\"]]#fill in with the columns you want to predict\n",
    "y_train = train[\"Team1Win?\"]\n",
    "\n",
    "x_test = test[[\"Team1SRS\"]]# fill in with the same columns as x_train\n",
    "y_test = test[\"Team1Win?\"]\n",
    "\n",
    "#build your model\n",
    "mod_bball = KNeighborsClassifier()# could use a different one instead, e.g., LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "mod_bball.fit(x_train, y_train)\n",
    "bball_pred = mod_bball.predict(x_test)\n",
    "print(\"accuracy: \", metrics.accuracy_score(bball_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
